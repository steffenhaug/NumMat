{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2:  Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a quick reminder of what we did in Lecture 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\DeclareMathOperator{\\Div}{div}\n",
    "\\DeclareMathOperator{\\Grad}{grad}\n",
    "\\DeclareMathOperator{\\Curl}{curl}\n",
    "\\DeclareMathOperator{\\Rot}{rot}\n",
    "\\DeclareMathOperator{\\ord}{ord}\n",
    "\\DeclareMathOperator{\\Kern}{ker}\n",
    "\\DeclareMathOperator{\\Image}{im}\n",
    "\\DeclareMathOperator{\\spann}{span}\n",
    "\\DeclareMathOperator{\\rank}{rank}\n",
    "\\DeclareMathOperator{\\dist}{dist}\n",
    "\\DeclareMathOperator{\\diam}{diam}\n",
    "\\DeclareMathOperator{\\sig}{sig}\n",
    "\\DeclareMathOperator{\\Id}{Id}\n",
    "\\newcommand{\\RR}{\\mathbb{R}}\n",
    "\\newcommand{\\NN}{\\mathbb{N}}\n",
    "\\newcommand{\\VV}{\\mathbb{V}}\n",
    "\\newcommand{\\dGamma}{\\,\\mathrm{d} \\Gamma}\n",
    "\\newcommand{\\dGammah}{\\,\\mathrm{d} \\Gamma_h}\n",
    "\\newcommand{\\dx}{\\,\\mathrm{d}x}\n",
    "\\newcommand{\\dy}{\\,\\mathrm{d}y}\n",
    "\\newcommand{\\ds}{\\,\\mathrm{d}s}\n",
    "\\newcommand{\\dt}{\\,\\mathrm{d}t}\n",
    "\\newcommand{\\dS}{\\,\\mathrm{d}S}\n",
    "\\newcommand{\\dV}{\\,\\mathrm{d}V}\n",
    "\\newcommand{\\dX}{\\,\\mathrm{d}X}\n",
    "\\newcommand{\\dY}{\\,\\mathrm{d}Y}\n",
    "\\newcommand{\\dE}{\\,\\mathrm{d}E}\n",
    "\\newcommand{\\dK}{\\,\\mathrm{d}K}\n",
    "\\newcommand{\\dM}{\\,\\mathrm{d}M}\n",
    "\\newcommand{\\cd}{\\mathrm{cd}}\n",
    "\\newcommand{\\onehalf}{\\frac{1}{2}}\n",
    "\\newcommand{\\bfP}{\\boldsymbol P}\n",
    "\\newcommand{\\bfx}{\\boldsymbol x}\n",
    "\\newcommand{\\bfy}{\\boldsymbol y}\n",
    "\\newcommand{\\bfa}{\\boldsymbol a}\n",
    "\\newcommand{\\bfu}{\\boldsymbol u}\n",
    "\\newcommand{\\bfv}{\\boldsymbol v}\n",
    "\\newcommand{\\bfe}{\\boldsymbol e}\n",
    "\\newcommand{\\bfb}{\\boldsymbol b}\n",
    "\\newcommand{\\bfc}{\\boldsymbol c}\n",
    "\\newcommand{\\bfq}{\\boldsymbol q}\n",
    "\\newcommand{\\bfy}{\\boldsymbol y}\n",
    "\\newcommand{\\bff}{\\boldsymbol f}\n",
    "\\newcommand{\\bfp}{\\boldsymbol p}\n",
    "\\newcommand{\\bft}{\\boldsymbol t}\n",
    "\\newcommand{\\bfj}{\\boldsymbol j}\n",
    "\\newcommand{\\bfB}{\\boldsymbol B}\n",
    "\\newcommand{\\bfV}{\\boldsymbol V}\n",
    "\\newcommand{\\bfE}{\\boldsymbol E}\n",
    "\\newcommand{\\bfB}{\\boldsymbol B}\n",
    "\\newcommand{\\bfzero}{\\boldsymbol 0}\n",
    "$$\n",
    "## Reduced QR Factorization\n",
    "\n",
    "Let $A \\in \\RR^{m,n}$ and\n",
    "assume that we have a (full) $QR$ factorization such that\n",
    "\n",
    "\\begin{align}\n",
    "A = \n",
    "Q\n",
    "\\begin{pmatrix}\n",
    "\\widehat{R}\n",
    "\\\\\n",
    "0\n",
    "\\end{pmatrix} \\in \\RR^{m,n}\n",
    "\\end{align}\n",
    "where $Q = (\\bfq_1 | \\cdots | \\bfq_m) \\in O(m)$ is a orthogonal matrix, and \n",
    "$\\widehat{R} \\in \\RR^{n,n}$ is an upper triangular matrix.\n",
    "\n",
    "Then the __full__ $QR$ factorization can be transformed\n",
    "into a __reduced__ $QR$ factorizations of the form\n",
    "\\begin{align}\n",
    "A = \n",
    "\\widehat{Q}\n",
    "\\widehat{R}\n",
    " \\in \\RR^{m,n}\n",
    "\\end{align}\n",
    "with $\\widehat{Q} = (\\bfq_1 | \\cdots | \\bfq_n) \\in  \\RR^{m,n}$\n",
    "satisfying $\\widehat{Q}^T \\widehat{Q} = \\Id_n \\in \\RR^{n,n}$. Here $\\Id_n$ denotes\n",
    "the $n \\times n$ Identity matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall from Lecture 7 that we can solve the least squares problem (l.s.p) by using the full QR factorization as follows:\n",
    "\n",
    "1) Define\n",
    "\\begin{align*}\n",
    "Q^T \\bfb \n",
    "= \\begin{pmatrix}\n",
    "\\bfb_1\n",
    "\\\\\n",
    "\\bfb_2\n",
    "\\end{pmatrix}\n",
    "\\end{align*}\n",
    "with $\\bfb_1 \\in \\RR^n$ and $\\bfb_2 \\in \\RR^{m-n}$.\n",
    "\n",
    "2) Solve \n",
    "$$\n",
    "\\widehat{R} \\bfx = \\bfb_1\n",
    "$$\n",
    "\n",
    "Note that $\\bfb_1 = \\widehat{Q}^T \\bfb$ so\n",
    "to solve the l.s.p you only need to compute the __reduced__ $QR$ factorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gram-Schmidt Orthogonalization\n",
    "\n",
    "\n",
    "We quickly review the Gram-Schmidt orthogonalization method and show that\n",
    "it in fact can be used to compute the reduced $QR$ factorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\{\\bfa_1,\\ldots,\\bfa_n\\} \\subset \\RR^m$ $n$ linear independent\n",
    "vectors in $\\RR^m$. The Gram-Schmidt orthogonalization process\n",
    "allows to orthogonalizes that set, that means, we can construct\n",
    "a set $\\{\\bfq_1, \\ldots, \\bfq_n \\}$ of orthogonal (orthonormal) vectors which have the same span as the original set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{alignat*}{3}\n",
    "\\bfy_1 &:= \\bfa_1, \\quad & &\\bfq_1 := \\dfrac{\\bfy_1}{\\|\\bfy_1\\|}\n",
    "\\\\\n",
    "\\bfy_2 &:= \\bfa_2 - \\langle \\bfq_1, \\bfa_2 \\rangle \\bfq_1, \\quad & &\\bfq_2 := \\dfrac{\\bfy_2}{\\|\\bfy_2\\|}\n",
    "\\\\\n",
    "\\ldots \n",
    "\\\\\n",
    "\\bfy_k &:= \\bfa_k - \\sum_{i=1}^{k-1} \\langle \\bfq_i, \\bfa_k \\rangle \\bfq_i, \\quad & &\\bfq_k := \\dfrac{\\bfy_k}{\\|\\bfy_k\\|}\n",
    "\\\\\n",
    "\\ldots\n",
    "\\\\\n",
    "\\bfy_n &:= \\bfa_n - \\sum_{i=1}^{n-1} \\langle \\bfq_i, \\bfa_n \\rangle \\bfq_i, \\quad & &\\bfq_n := \\dfrac{\\bfy_n}{\\|\\bfy_n\\|}\n",
    "\\end{alignat*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we use that $\\bfa_i$ rewrite as\n",
    "\n",
    "\\begin{align*}\n",
    "\\bfa_1 &:= \\underbrace{\\| \\bfy_1\\|}_{r_{11}} \\bfq_1\n",
    "\\\\\n",
    "\\bfa_2 &:= \\underbrace{\\| \\bfy_2 \\|}_{r_{22}} \\bfq_2 \n",
    "+ \\underbrace{\\langle \\bfq_1, \\bfa_2 \\rangle}_{r_{12}} \\bfq_1\n",
    "\\\\\n",
    "\\ldots \n",
    "\\\\\n",
    "\\bfa_k &:= \\underbrace{\\| \\bfy_k \\|}_{r_{kk}} \\bfq_k + \\sum_{i=1}^{k-1} \\underbrace{\\langle \\bfq_i, \\bfa_k \\rangle}_{r_{ik}} \\bfq_i\n",
    "\\\\\n",
    "\\ldots\n",
    "\\\\\n",
    "\\bfa_n &:= \\underbrace{\\| \\bfy_n \\|}_{r_{nn}} \\bfq_n + \\sum_{i=1}^{n-1} \\underbrace{\\langle \\bfq_i, \\bfa_n \\rangle }_{r_{in}}\\bfq_i\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So turning back to a matrix $A \\in \\RR^{m,n}$ with $\\rank(A) = n$,\n",
    "we write $A$ in terms of it column vectors\n",
    "\\begin{align}\n",
    "A &= ( \\bfa_1 | \\bfa_2 | \\ldots | \\bfa_n ) \\quad \\text{and define}\n",
    "\\\\\n",
    "\\widehat{Q} &:= ( \\bfq_1 | \\bfq_2 | \\ldots | \\bfq_n ) \\in \\RR^{m,n}\n",
    "\\end{align}\n",
    "Then applying the Gram-Schmidt algorithms as above to the column vectors of $A$ leads  us the __reduced__ $QR$ factorization.\n",
    "\n",
    "\\begin{align*}\n",
    "( \\bfa_1 | \\bfa_2 | \\ldots | \\bfa_n )\n",
    "= \n",
    "( \\bfq_1 | \\bfq_2 | \\ldots | \\bfq_n )\n",
    "\\begin{pmatrix}\n",
    "r_{11} & r_{12} & \\cdots & r_{1n}\n",
    "\\\\\n",
    "& r_{22} & \\cdots & r_{2n}\n",
    "\\\\\n",
    "& & \\ddots & \\vdots\n",
    "\\\\\n",
    "& & & r_{nn}\n",
    "\\end{pmatrix}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Task 1\n",
    "\n",
    "Consider the Pseudocode\n",
    "\n",
    "### Algorithm 1\n",
    "\n",
    "Let $\\bfa_1, \\ldots, \\bfa_n \\in \\RR^{m}$ be linearly independent vectors.\n",
    "\n",
    "```\n",
    "for j = 1,2,...,n\n",
    "    y = a_j\n",
    "    for i = 1,2,...,j-1\n",
    "        r_ij = q_i^T a_j\n",
    "        y = y - r_ij q_i\n",
    "    end\n",
    "    r_jj = ||y||\n",
    "    q_j = y/r_jj\n",
    "end \n",
    "```\n",
    "\n",
    "Write a small Python function ```qr_factor``` to compute the reduced QR factorization for a given matrix $A$  by completing the following\n",
    "code (But read the hints below before you start!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qr_factor(A):\n",
    "    m, n = A.shape\n",
    "    # As starting point for Q take a copy of A\n",
    "    Q = A.copy()\n",
    "    R = np.zeros((n, n), dtype=float)\n",
    "    \n",
    "    for j in range(n):\n",
    "        y = Q[:, j]\n",
    "        for i in range(j):\n",
    "            R[i, j] = Q[:, i].dot(A[:, j])\n",
    "            y = y - R[i, j] * Q[:, i]\n",
    "        R[j, j] = la.norm(y)\n",
    "        Q[:, j] = (1 / R[j, j]) * y\n",
    "    return Q, R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your program with the the matrix\n",
    "\\begin{align*}\n",
    "A =\n",
    "\\begin{pmatrix}\n",
    "1 & -4\n",
    "\\\\\n",
    "2 & 3\n",
    "\\\\\n",
    "2 & 2\n",
    "\\end{pmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "Check whether the return matrices satisfy\n",
    "* $\\widehat{Q}^T \\widehat{Q} = \\Id $ (modulo machine precision errors!)\n",
    "* $\\widehat{Q} \\widehat{R} = A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, -4],\n",
    "              [2,  3],\n",
    "              [2,  2]], dtype=float)\n",
    "\n",
    "Q, R = qr_factor(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 2.77555756e-17],\n",
       "       [2.77555756e-17, 1.00000000e+00]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(Q).dot(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -4.],\n",
       "       [ 2.,  3.],\n",
       "       [ 2.,  2.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.dot(R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hints and useful code snippets\n",
    "\n",
    "Here are some hints derived from the received questions and observed\n",
    "pitfalls on Thursday. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When you define arrays make always sure that they are of _float type_ otherwise you might observe strange side effects if the elements are interpreted as _integers_ types.\n",
    "So either explicit define you numpy arrays using the keyword `dtype =  float` or write all (or at least __one__ of them) numbers as floating point, e.g. $1.0$ instead of 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = np.array([[1, 2, 3],\n",
    "               [4, 5, 6],\n",
    "               [7, 8, 9]])\n",
    "print(A1.dtype)\n",
    "\n",
    "A1 = np.array([[1, 2, 3],\n",
    "               [4, 5, 6],\n",
    "               [7, 8, 9]], dtype=float)\n",
    "print(A1.dtype)\n",
    "\n",
    "A1 = np.array([[1.0, 2, 3],\n",
    "               [4, 5, 6],\n",
    "               [7, 8, 9]])\n",
    "print(A1.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As you also want to compute the $Q$ matrix, store the $q_i$ as column vectors\n",
    "  of this matrix.  \n",
    "* ```q_i^T a_j``` is just a the matrix way to write the scalar product \n",
    "  $\\langle \\bfq_i, \\bfa_j \\rangle$ \n",
    "  between the i-th column vector of $Q$ and j-th column vector of \n",
    "  $A$, see also the the code snippets below for how to compute\n",
    "  scalar products or arrays in Python.\n",
    "* Remember that indexing in Python starts with $0$. If you want do to a \n",
    "  loop over\n",
    "  some integers, use the ```range(n)``` function in Python, which\n",
    "  returns a list of integers $[0, 1, \\ldots, n-1]$ and \n",
    "  __excludes__ $n$. So in the outermost loop in Algorithm should\n",
    "  use a ```range(n)```. The range for the innermost loop over $j$ \n",
    "  is a bit \"tricky\" since don't shift the entire range as in the   \n",
    "  outermost loop! Instead it should be read as \"Start from the first index\n",
    "  (which in Python is 0) and run until one index below the outermost running index, \n",
    "  so the range for the innermost range should be `range(j)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reminder on useful operations on arrays and vectors in numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A1 = np.array([[1, 2, 3],\n",
    "               [4, 5, 6],\n",
    "               [7, 8, 9]])\n",
    "A2 = np.array([[10, 20, 30],\n",
    "               [40, 50, 60],\n",
    "               [70, 80, 90]])\n",
    "A1*A2 # elementwise product\n",
    "\n",
    "# Creating two 4x3 matrices and one 3x4 matrix\n",
    "A1 = np.arange(12).reshape(4,3)\n",
    "A2 = 10*np.arange(12).reshape(4,3)\n",
    "A3 = 100*np.arange(12).reshape(3,4)\n",
    "\n",
    "\n",
    "print(\"A1 = \")\n",
    "print(A1)\n",
    "\n",
    "print(\"A2 = \")\n",
    "print(A2)\n",
    "\n",
    "print(\"A3 = \")\n",
    "print(A3)\n",
    "\n",
    "print(\"A1[1,2] = \")\n",
    "print(A1[1,2])\n",
    "\n",
    "# Similar effect, but  first version is preferred\n",
    "print(A1[1][2])\n",
    "\n",
    "# Get row nr 0 and nr 1. Remember that we start counting at 0.\n",
    "print(\"Extract Row 0 from A1\")\n",
    "print(A1[0,:])\n",
    "\n",
    "\n",
    "print(\"Extract Row 3 from A1\")\n",
    "print(A1[3,:])\n",
    "\n",
    "# Get 3rd column\n",
    "print(\"Extract Column 2 from A1\")\n",
    "print(A1[:,2])\n",
    "\n",
    "# If you want to compute the scalar product between, e.g. column vector 1 of A1\n",
    "# and column vector 2 of A2, you can simply do\n",
    "\n",
    "print(\"<a1_1, a2_2> =  \")\n",
    "\n",
    "A1[:,1]@A2[:,2]\n",
    "\n",
    "# If you want to compute the matrix product A1*A3\n",
    "# you can simply write \n",
    "print(\"A1*A3 =  \")\n",
    "A1@A3\n",
    "\n",
    "# Compute norms\n",
    "from numpy.linalg import norm\n",
    "# Compute 2-norm of the 0th colum vector of A1\n",
    "print(\"||a_1||_2 =\")\n",
    "print(norm(A1[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Task 2\n",
    "\n",
    "We consider the following __data fitting problem__: \n",
    "\n",
    "Let $\\{x_i\\}_{i=0}^{m-1}$ a set of $m$ equally space points\n",
    "of an interval $[a,b]$, that is, $x_0 = a$, $x_{m-1} = b$ \n",
    "and $|x_k - x_{k-1}| = (b-a)/(m-1) $. \n",
    "\n",
    "Let $n \\in \\NN$ some integer and \n",
    "assume we have the $m$ data points $y_i = P_{n-1}(x_i)$ for $i=0,\\ldots m-1$.\n",
    "where the function $P_{n-1}$ is a polynomial of order $n-1$ is a  is given\n",
    "\n",
    "$$\n",
    "P_{n-1}(x) = \\sum_{k=0}^{n-1} x^k\n",
    "$$\n",
    "\n",
    "Now we want to find the least-squares polynomial $\\widetilde{P}_{l}(x) = \\sum_{k=0}^l c_k x^k$  fitting the data $\\{(x_i, y_i)\\}_{i=0}^{m-1}$ in a least-squares sense.\n",
    "\n",
    "To do that we want to \"solve\" (as good as possible) the problem\n",
    "\\begin{align*}\n",
    "A =\n",
    "\\begin{pmatrix}\n",
    "1 & x_0 & x_0^2 & \\cdots & x_0^l\n",
    "\\\\\n",
    "1 & x_1 & x_1^2 & \\cdots & x_1^l\n",
    "\\\\\n",
    "\\vdots & \\vdots & \\vdots& & \\vdots\n",
    "\\\\\n",
    "1 & x_{m-1} & x_{m-1}^2 & \\cdots & x_{m-1}^l\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "c_0 \n",
    "\\\\\n",
    "c_1\n",
    "\\\\\n",
    "\\vdots\n",
    "\\\\\n",
    "c_l\n",
    "\\end{pmatrix}\n",
    "=\n",
    "\\begin{pmatrix}\n",
    "y_0\n",
    "\\\\\n",
    "y_1\n",
    "\\\\\n",
    "\\vdots\n",
    "\\\\\n",
    "y_{m-1}\n",
    "\\end{pmatrix}\n",
    "= \\bfy\n",
    "\\end{align*}\n",
    "\n",
    "We can compute the coefficient vector $\\bfc$ by solving the l.s.p\n",
    "$\\min \\| A \\bfc - \\bfy \\|_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we choose $l = n-1$ so that we know by construction of the data points\n",
    "$y_i$ that the exact answer should be\n",
    "\\begin{align}\n",
    "\\bfc_{ex} = \n",
    "\\begin{pmatrix}\n",
    "1 , 1, \\ldots, 1 \n",
    "\\end{pmatrix}^T \\in \\RR^n\n",
    "\\end{align}\n",
    "\n",
    "Now proceed as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1)__ Choose the interval end points $a = 2$, $b=4$, the number of data points to be  \n",
    "   $m = 11$. Now for polynomial orders $n-1 = 0, 1, 2, 3, 4, 5$,\n",
    "   compute $\\bfc_n \\in \\RR^n$ using the QR factorization you implemented above.\n",
    "   How does the expected solution compares with the computed one?\n",
    "   In particular, compute and tabulate $\\| \\bfc - \\bfc_{ex} \\|_2$ as \n",
    "   function of $n$. Pay attention to $n=5$ vs. $n=6$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2.220446049250313e-16\n",
      "2 5.978733960281817e-16\n",
      "3 1.93234566207454e-12\n",
      "4 1.1225235250501518e-09\n",
      "5 1.2622346145794948e-06\n",
      "6 0.002889213464223681\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "\n",
    "# Define x data points using linspace\n",
    "x = np.linspace(2,4,num=11, endpoint=True)\n",
    "\n",
    "for n in range(1, 7): # n = 1 .. 6\n",
    "    l = n - 1 # l = 0..5\n",
    "    \n",
    "    # Create the exact polynomial with all coeff. = 1\n",
    "    c_ex = np.array([1 for _ in range(n)]) # 1 in R^n, exact polynomial\n",
    "    poly = np.poly1d(c_ex)\n",
    "    \n",
    "    # Calculate the y-data\n",
    "    y = poly(x_data)\n",
    "    \n",
    "    A = np.array([x**k for k in range(0,n)], dtype=float)\n",
    "    A = A.transpose()\n",
    "    \n",
    "    Q, R = qr_factor(A)\n",
    "    \n",
    "    # Remains now to solve\n",
    "    #   (QR) c = y <=> Rc = Q^T y = b\n",
    "    b = np.transpose(Q).dot(y)\n",
    "    \n",
    "    c = la.solve_triangular(R, b)\n",
    "\n",
    "    diff = la.norm(c - c_ex)\n",
    "    print(n, diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful code snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as la\n",
    "\n",
    "# Define x data points using linspace\n",
    "x_data = np.linspace(2,4,num=11, endpoint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define polynomials you could use ```poly1d```, see [here](https://docs.scipy.org/doc/numpy-1.17.0/reference/generated/numpy.poly1d.html?highlight=poly1d#numpy.poly1d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define y data points\n",
    "poly_grad = 5\n",
    "\n",
    "poly_coeff = np.array([1 for _ in range(poly_grad)])\n",
    "poly = np.poly1d(poly_coeff)\n",
    "y_data = poly(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define matrix A\n",
    "mono = lambda x, k: x**k\n",
    "A = np.array([mono(x_data,k) for k in range(0,poly_grad+1)], dtype=float)\n",
    "A = A.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the $QR$ factorization and computation of the proper rhs vector $\\bfb_1$ you \n",
    "need to solve $\\widehat{R} \\bfx = \\bfb_1$. To solve a system with a\n",
    "triangular matrix you can either use your code from the previous lab or\n",
    "the built-in function [solve_triangular](https://docs.scipy.org/doc/scipy-1.3.0/reference/generated/scipy.linalg.solve_triangular.html?highlight=solve_triangular#scipy.linalg.solve_triangular)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "I think it was very hard to understand what exactly this question asked me to do. It looks like the error increases as n increases, but i can't see any reason to pay attention to $n = 5$ vs. $n=6$, which leads me to\n",
    "believe that i may have misunderstood what i was asked to do. The only \"difference\" is that the error grows so large that jupyter stops printing the numbers using scientific notation by default, which is completely arbitrary, of course.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__b)__ Next, you are asked to implemented a QR factorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qr_factor_modified(A):\n",
    "    m, n = A.shape\n",
    "    # As starting point for Q take a copy of A\n",
    "    Q = A.copy()\n",
    "    R = np.zeros((n, n), dtype=float)\n",
    "    \n",
    "    for j in range(n):\n",
    "        y = Q[:, j]\n",
    "        for i in range(j):\n",
    "            R[i, j] = Q[:, i].dot(y)\n",
    "            y = y - R[i, j] * Q[:, i]\n",
    "        R[j, j] = la.norm(y)\n",
    "        Q[:, j] = (1 / R[j, j]) * y\n",
    "    return Q, R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based the __modified Gram-Schmidt orthogonalization__:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "\n",
    "Let $\\bfa_1, \\ldots, \\bfa_n \\in \\RR^{m}$ be linearly independent vectors.\n",
    "\n",
    "```\n",
    "for j = 1,2,...,n\n",
    "    y = a_j\n",
    "    for i = 1,2,...,j-1\n",
    "        r_ij = q_i^T y\n",
    "        y = y - r_ij q_i\n",
    "    end\n",
    "    r_jj = ||y||\n",
    "    q_j = y/r_jj\n",
    "end \n",
    "```\n",
    "\n",
    "(Reminder for myself what the other one looked like)\n",
    "```\n",
    "for j = 1,2,...,n\n",
    "    y = a_j\n",
    "    for i = 1,2,...,j-1\n",
    "        r_ij = q_i^T a_j # difference is here\n",
    "        y = y - r_ij q_i\n",
    "    end\n",
    "    r_jj = ||y||\n",
    "    q_j = y/r_jj\n",
    "end \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you spot the difference to the standard Gram-Schmidt orthogonalization method?\n",
    "Explain, why this modfied method still a orthogonalization procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "I made a comment in the pseudocode code pointing out where the difference is.\n",
    "$y$ and $A_j$ are parallel, so the projection onto them is pointing in the same direction for all vectors, but it has a different length. The procedure still works because the vectors are normalized.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__c)__ The modified Gram-Schmidt process  is actually more stable with respect to rounding errors than the original/classical one. Test this claim and repeat the experiment from a) but now use the ```qr_factor_modified``` function based on the modified Gram-Schmidt method.\n",
    "How does the solution $\\bfc_n$ compares the one computed with the original Gram-Schmidt method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    This task has subtasks 1), b), and c), so i am assuming a) refers \n",
    "    to 1), because this document has no subtask a) anywhere.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2.220446049250313e-16\n",
      "2 5.978733960281817e-16\n",
      "3 1.7292627766211682e-12\n",
      "4 5.797794416289898e-10\n",
      "5 1.5359453897663702e-07\n",
      "6 4.031625199348614e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define x data points using linspace\n",
    "x = np.linspace(2,4,num=11, endpoint=True)\n",
    "\n",
    "for n in range(1, 7): # n = 1 .. 6\n",
    "    l = n - 1 # l = 0..5\n",
    "    \n",
    "    # Create the exact polynomial with all coeff. = 1\n",
    "    c_ex = np.array([1 for _ in range(n)]) # 1 in R^l\n",
    "    poly = np.poly1d(c_ex)\n",
    "    \n",
    "    # Calculate the y-data\n",
    "    y = poly(x_data)\n",
    "    \n",
    "    A = np.array([x**k for k in range(0,n)], dtype=float)\n",
    "    A = A.transpose()\n",
    "    \n",
    "    Q, R = qr_factor_modified(A)\n",
    "    \n",
    "    # Remains now to solve\n",
    "    #   (QR) c = y <=> Rc = Q^T y = b\n",
    "    b = np.transpose(Q).dot(y)\n",
    "    \n",
    "    c = la.solve_triangular(R, b)\n",
    "\n",
    "    diff = la.norm(c - c_ex)\n",
    "    print(n, diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "The error seems to in fact be smaller,\n",
    "but i still see little reason to pay special attantion\n",
    "    to $n = 5$ vs. $n=6$.\n",
    "</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
